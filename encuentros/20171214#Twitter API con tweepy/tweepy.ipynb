{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recopilación de tweets con tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En este cuaderno aprenderemos cómo usar la API de Twitter para descargarnos tweets según los criterios de búsqueda que nosotros mismo definamos y guardar los datos que necesitamos en un archivo *csv*.   \n",
    "\n",
    "Twitter tiene varias APIs, y nosotros nos vamos a conectar a la [Search API](https://developer.twitter.com/en/docs/tweets/search/overview) que permite recabar tweets publicados en los últimos siete días. Si quisieramos ampliar la búsqueda a un periodo más largo, tendríamos que recurrir a una versión Premium de esa misma API o algún otro servicio de pago. También podríamos hacerlo con un scraper que no utulice la API de Twitter, como puede ser [este](https://github.com/taspinar/twitterscraper).   \n",
    "\n",
    "Python tiene una librería llamada **tweepy** que permite acceder a las APIs de Twitter de una forma muy cómoda. Por supuesto que vamos a darle uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtener las credenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos utilizar una API de Twitter, tendremos que registrar una aplicación en el [Application Management](https://apps.twitter.com) de nuestra cuenta.\n",
    "\n",
    "Ahí se nos pedirá que demos un nombre a nuestra aplicación, pongamos una descripción y apuntemos a una URL (si no tienes tu propia web, pon la URL que quieras). Cuando le des a *Create your Twitter application*, se creará tu aplicación y podrás ver tus dos claves: **Consumer Key** y **Consumer Secret**.\n",
    "\n",
    "Pero esto no es todo, porque todavía falta obtener los tokens de acceso. Para eso tienes que abrir la pestaña *Key and Access Tokens* y después de darle a *Generate my Access Token and Token Secret* verás tus **Access Token** y **Access Token Secret**.\n",
    "      \n",
    "En principio, puedes guardar tus credenciales en este mismo cuaderno, pero imagínate que quieras compartir tu código con más gente, igual no te interesa que se sepan tus claves personales. Para hacer las cosas bien, crea un archivo llamado, por ejemplo, `secret.py`, con el siguiente contenido:\n",
    "\n",
    "```\n",
    "CONSUMER_KEY = 'copia tu Consumer Key aquí'\n",
    "CONSUMER_SECRET = 'copia tu Consumer Secret aquí'\n",
    "ACCESS_TOKEN = 'copia tu Access Token aquí'\n",
    "ACCESS_SECRET = 'copia tu Acces Token Secret aquí'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparar el esqueleta del programa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero haremos los *imports* necesarios. Además de la librería *tweepy* necesitaremos la de *csv* que nos permitirá crear archivos de este tipo para almacenar nuestros datos. Por último, tenemos que importar todas nuestras claves desde el archivo *secret.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "from secret import CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora viene lo más interesante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) # creamos un objeto de autentificación de la aplicación\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET) # añadimos nuestra autentificación como usuario\n",
    "\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "                 wait_on_rate_limit_notify=True) # creamos un objeto API que hará de interfaz con la API Twitter\n",
    "\n",
    "# wait_on_rate_limit pone la API en espera cada vez que alcanzamos el límite de llamada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi lo tenemos todo preparado para empezar a recopilar tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Con la autorización OAuth que hemos utilizado podemos obtener hasta 18000 tweets cada 15 minutos. También podríamos haber autentificado solo la aplicación sin autentificarnos como usuario, sustituyendo la primera línea por `auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)` y quitando la segunda. Esto nos habría permitido obtenero hasta 45000 tweets cada 15 minutos. Sin embargo, este tipo de autentificación tiene [algunas limitaciones](https://developer.twitter.com/en/docs/basics/authentication/overview/application-only), por eso nos hemos decantado por la autentificación OAuth, aunque ninguna de estas limitaciones nos hubiera impedido hacer lo que nos hemos propuesto en este cuaderno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mi primer llamada a la API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a empezar por una tarea muy sencilla: encontraremos 20 tweets con el hashtag \"#NLP\". Para ello utilizaremos el `Cursor` de `tweepy`. Luego imprimiremos los resultados por pantalla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tweets = tweepy.Cursor(api.search, q=\"#NLP\", count=100).items(100)\n",
    "\n",
    "# api.search: pasamos al Cursor nuestro objeto API con el método que queremos utilizar (search, en nuestro caso)\n",
    "# q: lo que queremos encontrar en los tweets\n",
    "# count: cuántos tweets queremos encontrar por request (el máximo es 100)\n",
    "# .items(un número): número total de tweets que queremos recopilar\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(json.dumps(tweet._json, indent=4)) # con un simple print(tweet) habríamos obtenido un resultado menos legible \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que la aplicación está funcionando. La API devuelve los tweets en el formato `json` y viendo lo que se ha imprimido, se puede ver qué atributos tiene cada tweet además del propio texto.\n",
    "\n",
    "Pero no nos damos por satisfechos y a continuación vamos a intentar conseguir lo siguiente:\n",
    "     \n",
    "     * decidir qué atributos de cada tweet nos interesan (¿para qué almacenar cosas que no vamos a utilizar?)\n",
    "     * guardar nuestros tweets en un archivo csv\n",
    "     * refinar nuestra búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Seleccionar los atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a decir que para cada tweet nos gustaría quedarnos con los siguientes datos:\n",
    "\n",
    "     * id del tweet (en formato string)\n",
    "     * fecha y hora del tweet\n",
    "     * texto del tweet\n",
    "     * id del autor del tweet\n",
    "     * screen name del autor\n",
    "     * nombre del autor\n",
    "     * ubicación del autor (la que pone en su perfil, no es lo mismo que la geolocalización del tweet)\n",
    "     \n",
    "Identificaremos los nombres de los atributos gracias al json que hemos imprimido y accederemos a ellos haciendo `tweet.nombre_del_atributo` (`tweet` aquí es el nombre que hemos definido nosotros para nuestro objetos *tweet*, podríamos haber usado cualquier otro nombre)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Guardar los datos en un csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar nuestros tweets, utilizaremos las posibilidades de la librería `csv` que ya hemos importado.   \n",
    "\n",
    "De momento seguiremos con la buscando tweets con el hashtag #NLP, pero ya podremos seleccionar los atributos que nos interesa guardar y \"desechar\" el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ups/tweets.csv', 'a', encoding='utf-8') as f: # abro mi archivo en modo \"escritura\"\n",
    "    csvWriter = csv.writer(f) # creamos un objeto de tipo \"csv.writer\", le pasamos nuestro archivo\n",
    "    \n",
    "    # lanzamos una búsqueda e iteramos por los tweets\n",
    "    for tweet in tweepy.Cursor(api.search, q=\"#nlp\", count=50).items(50):\n",
    "        # para cada tweet, escribimos una fila en el archivo\n",
    "        csvWriter.writerow([tweet.id,\n",
    "                            tweet.text.replace(\"\\n\",\" \"),\n",
    "                            tweet.user.id,\n",
    "                            tweet.user.screen_name                       \n",
    "                           ])\n",
    "        \n",
    "# TE TOCA: añade la fecha/hora de creación del tweet, el nombre del autor y su ubicación a la lista de atributos guardados.\n",
    "\n",
    "# TE TOCA: por la manera de la que hemos abierto el archivo, cada vez que ejecutemos el código el archivo se va\n",
    "# a crear de nuevo y los datos ya guardados se van a eliminar. Para hacer que la nueva información se añada a la\n",
    "# que ya existe, solo hay que cambiar una letra en nuestro código. ¿Cómo hacerlo? (pregunta a Google)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Si vas a querer abrir tu csv en Excel, es posible que te encuentres con una serie de problemas:\n",
    "\n",
    "1. Los saltos de línea (\"\\n\") en el texto del tweet se interpretarán como el comienzo de una nueva fila (ya lo hemos solucionado más arriba eliminando los saltos de línea en `tweet.text`).\n",
    "2. Los caracteres non-ASCII aparecerán de forma \"rara\". Para solucionarlo, abre el archivo en un editor de texto plano, copia su contenido y pégalo a Excel.\n",
    "3. Excel no separará los datos por columnas. Lo puedes solucionar en la pestaña \"Data\" -> \"Text to Columns\".\n",
    "\n",
    "En principio, no tendrás ninguno de estos problemas si abres el archivo en Google Sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Refinar la búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, lo único que le hemos pedido a la API fue que nos trajera tweets con el hashtag #NLP, pero por supuesto podemos ponerle más filtros.  \n",
    "\n",
    "Una parte de estos filtros se definirá en la propia query (es decir, en el parámetro, \"q\"). Puedes encontrar una lista de estos operadores [aquí](https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators). Los otros filtros se pasarán como parámetros, los puedes encontrar  [aquí](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets).   \n",
    "\n",
    "Ahora vamos a retocar nuestro código para conseguir lo siguiente:\n",
    "\n",
    "   * buscar tweets con los hashtags #NLP y #python\n",
    "   * que contengan una imagen o un video\n",
    "   * que hayan sido tweeteados antes del 11/12/2017 (recuerda que solo se devuelven tweets de los 7 últimos días)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/tweets.csv', 'w', encoding='utf-8') as f: # abro mi archivo en modo \"escritura\"\n",
    "    csvWriter = csv.writer(f) # creo un objeto de tipo \"csv.writer\", le paso mi archivo\n",
    "    \n",
    "    # lanzo una búsqueda e itero por los tweets\n",
    "    for tweet in tweepy.Cursor(api.search, q=\"#nlp #python filter:media\", \n",
    "                               until=\"2017-12-11\", count=100).items(200):\n",
    "        # para cada tweet, escribo una fila en el archivo\n",
    "        csvWriter.writerow([tweet.id,\n",
    "                            tweet.text,\n",
    "                            tweet.user.id,\n",
    "                            tweet.user.screen_name                       \n",
    "                           ])\n",
    "        \n",
    "# TE TOCA: busca tweets \n",
    "    # que contengan los hashtags #nlp O #python\n",
    "    # que no sean retweets\n",
    "    # que estén escritos en español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Guardar las coordenadas de los tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra cosa que nos gustaría hacer es geolocalizar los tweets. Esta información está contenida en los atributos `geo`, `coordinates` y `place`.   \n",
    "\n",
    "`geo` y `coordinates` contienen exactamente los mismos datos: las coordenadas exactas desde las que se hizo el tweet. La diferencia consiste en que `geo` está semi-deprecado y que en `geo` primero se cita la latitud y luego la longitud, mientras que en `coordinates` es al revés. También si volvemos al json que hemos imprimido, veremos que los dos atributos contienen diccionarios, así que para acceder a las coordenadas tendremos que hacer `tweet.coordinates[\"coordinates\"]. \n",
    "\n",
    "La inmensa mayoría de los tweets no van a tener ningún dato en `geo` y `coordinates`, pero algunos sí, así que vamos a incluirlo en nuestro `csv` y a ver si pillamos por lo menos algunos tweets geolocalizados.\n",
    "\n",
    "En cuanto a `place` este contiene una geolocalización menos precisa del área desde la que se emitió el tweet. Los tweets conteniendo solo información de `place` (sin la de `geo` y `coordinates`) se dan con un poquito más de frecuencia, pero para no complicarnos la vida, no vamos a trabajar con `place` en este tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/tweets.csv', 'w', encoding='utf-8') as f: # abro mi archivo en modo \"escritura\"\n",
    "    csvWriter = csv.writer(f) # creamos un objeto de tipo \"csv.writer\", le pasamos nuestro archivo\n",
    "    \n",
    "    # lanzamos una búsqueda e iteramos por los tweets\n",
    "    for tweet in tweepy.Cursor(api.search, q=\"#Madrid\", \n",
    "                               until=\"2017-12-11\", count=100).items(1000):\n",
    "        # para cada tweet, escribimos una fila en el archivo\n",
    "        \n",
    "        if tweet.coordinates:\n",
    "            lat = tweet.coordinates[\"coordinates\"][1]\n",
    "            long = tweet.coordinates[\"coordinates\"][0]            \n",
    "        else:\n",
    "            long = None\n",
    "            lat = None\n",
    "        csvWriter.writerow([tweet.id,\n",
    "                            tweet.text,\n",
    "                            tweet.user.id,\n",
    "                            tweet.user.screen_name,\n",
    "                            lat,\n",
    "                            long\n",
    "                           ])\n",
    "        \n",
    "\n",
    "# TE TOCA: cambia el código para que el tweet solo se guarde en el csv si contiene coordenadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
